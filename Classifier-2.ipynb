{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train = pd.read_csv('train.csv')\n",
    "kaggle_test = pd.read_csv('test.csv')\n",
    "OUTPUT = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "kaggle_train = shuffle(kaggle_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = kaggle_train['comment_text']\n",
    "y_train = kaggle_train[OUTPUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max comment length: 1403\n",
      "No. of unique words: 210337\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "split_text = []\n",
    "max_len = 0\n",
    "for line in X_train:\n",
    "    split_line = text_to_word_sequence(line)\n",
    "    max_len = max(max_len, len(split_line))\n",
    "    split_text.extend(split_line)\n",
    "unique_word_set = set(split_text)\n",
    "\n",
    "print('Max comment length:', max_len)\n",
    "print('No. of unique words:', len(unique_word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'of': 3,\n",
       " 'and': 4,\n",
       " 'a': 5,\n",
       " 'you': 6,\n",
       " 'i': 7,\n",
       " 'is': 8,\n",
       " 'that': 9,\n",
       " 'in': 10,\n",
       " 'it': 11,\n",
       " 'for': 12,\n",
       " 'this': 13,\n",
       " 'not': 14,\n",
       " 'on': 15,\n",
       " 'be': 16,\n",
       " 'as': 17,\n",
       " 'have': 18,\n",
       " 'are': 19,\n",
       " 'your': 20,\n",
       " 'with': 21,\n",
       " 'if': 22,\n",
       " 'article': 23,\n",
       " 'was': 24,\n",
       " 'or': 25,\n",
       " 'but': 26,\n",
       " 'page': 27,\n",
       " 'wikipedia': 28,\n",
       " 'my': 29,\n",
       " 'an': 30,\n",
       " 'from': 31,\n",
       " 'by': 32,\n",
       " 'do': 33,\n",
       " 'at': 34,\n",
       " 'me': 35,\n",
       " 'about': 36,\n",
       " 'so': 37,\n",
       " 'talk': 38,\n",
       " 'what': 39,\n",
       " 'can': 40,\n",
       " 'there': 41,\n",
       " 'all': 42,\n",
       " 'has': 43,\n",
       " 'will': 44,\n",
       " 'please': 45,\n",
       " 'no': 46,\n",
       " 'would': 47,\n",
       " 'one': 48,\n",
       " 'like': 49,\n",
       " 'just': 50,\n",
       " 'they': 51,\n",
       " 'he': 52,\n",
       " 'which': 53,\n",
       " 'any': 54,\n",
       " 'been': 55,\n",
       " 'should': 56,\n",
       " 'more': 57,\n",
       " 'we': 58,\n",
       " \"don't\": 59,\n",
       " 'some': 60,\n",
       " 'other': 61,\n",
       " 'who': 62,\n",
       " 'here': 63,\n",
       " 'see': 64,\n",
       " 'also': 65,\n",
       " 'his': 66,\n",
       " 'think': 67,\n",
       " 'because': 68,\n",
       " 'know': 69,\n",
       " 'how': 70,\n",
       " 'edit': 71,\n",
       " 'am': 72,\n",
       " \"i'm\": 73,\n",
       " 'people': 74,\n",
       " 'why': 75,\n",
       " 'up': 76,\n",
       " 'only': 77,\n",
       " \"it's\": 78,\n",
       " 'out': 79,\n",
       " 'articles': 80,\n",
       " 'use': 81,\n",
       " 'when': 82,\n",
       " 'then': 83,\n",
       " 'time': 84,\n",
       " 'may': 85,\n",
       " 'were': 86,\n",
       " 'did': 87,\n",
       " 'them': 88,\n",
       " 'now': 89,\n",
       " 'being': 90,\n",
       " 'user': 91,\n",
       " 'their': 92,\n",
       " 'than': 93,\n",
       " 'thanks': 94,\n",
       " 'even': 95,\n",
       " 'get': 96,\n",
       " 'make': 97,\n",
       " 'good': 98,\n",
       " 'had': 99,\n",
       " 'well': 100,\n",
       " 'very': 101,\n",
       " 'information': 102,\n",
       " 'does': 103,\n",
       " 'could': 104,\n",
       " 'want': 105,\n",
       " 'deletion': 106,\n",
       " 'its': 107,\n",
       " 'such': 108,\n",
       " 'sources': 109,\n",
       " 'way': 110,\n",
       " 'name': 111,\n",
       " 'these': 112,\n",
       " 'first': 113,\n",
       " 'wp': 114,\n",
       " 'help': 115,\n",
       " 'pages': 116,\n",
       " 'new': 117,\n",
       " 'image': 118,\n",
       " 'source': 119,\n",
       " 'editing': 120,\n",
       " 'go': 121,\n",
       " 'need': 122,\n",
       " 'section': 123,\n",
       " 'say': 124,\n",
       " 'again': 125,\n",
       " 'edits': 126,\n",
       " 'thank': 127,\n",
       " 'where': 128,\n",
       " 'fuck': 129,\n",
       " 'made': 130,\n",
       " 'many': 131,\n",
       " 'much': 132,\n",
       " 'used': 133,\n",
       " 'really': 134,\n",
       " 'most': 135,\n",
       " 'deleted': 136,\n",
       " 'discussion': 137,\n",
       " 'find': 138,\n",
       " 'same': 139,\n",
       " 'into': 140,\n",
       " 'work': 141,\n",
       " 'those': 142,\n",
       " \"i've\": 143,\n",
       " 'since': 144,\n",
       " 'right': 145,\n",
       " 'point': 146,\n",
       " 'before': 147,\n",
       " 'after': 148,\n",
       " 'add': 149,\n",
       " 'read': 150,\n",
       " 'look': 151,\n",
       " 'over': 152,\n",
       " 'him': 153,\n",
       " 'take': 154,\n",
       " 'two': 155,\n",
       " 'still': 156,\n",
       " 'back': 157,\n",
       " 'wiki': 158,\n",
       " 'someone': 159,\n",
       " 'fact': 160,\n",
       " 'hi': 161,\n",
       " 'too': 162,\n",
       " 'list': 163,\n",
       " 'link': 164,\n",
       " 'own': 165,\n",
       " 'said': 166,\n",
       " 'something': 167,\n",
       " 'going': 168,\n",
       " 'blocked': 169,\n",
       " '1': 170,\n",
       " '2': 171,\n",
       " 'stop': 172,\n",
       " \"you're\": 173,\n",
       " 'content': 174,\n",
       " 'without': 175,\n",
       " 'block': 176,\n",
       " 'under': 177,\n",
       " 'history': 178,\n",
       " 'http': 179,\n",
       " 'our': 180,\n",
       " 'added': 181,\n",
       " 'utc': 182,\n",
       " 'editors': 183,\n",
       " 'another': 184,\n",
       " 'removed': 185,\n",
       " 'her': 186,\n",
       " 'might': 187,\n",
       " 'welcome': 188,\n",
       " 'note': 189,\n",
       " 'however': 190,\n",
       " 'free': 191,\n",
       " 'place': 192,\n",
       " 'sure': 193,\n",
       " 'case': 194,\n",
       " 'never': 195,\n",
       " \"doesn't\": 196,\n",
       " 'done': 197,\n",
       " 'us': 198,\n",
       " 'vandalism': 199,\n",
       " 'reason': 200,\n",
       " 'put': 201,\n",
       " 'comment': 202,\n",
       " 'personal': 203,\n",
       " 'better': 204,\n",
       " \"that's\": 205,\n",
       " 'yourself': 206,\n",
       " 'using': 207,\n",
       " 'seems': 208,\n",
       " 'ask': 209,\n",
       " 'actually': 210,\n",
       " 'question': 211,\n",
       " 'off': 212,\n",
       " 'while': 213,\n",
       " 'feel': 214,\n",
       " 'anything': 215,\n",
       " 'believe': 216,\n",
       " 'links': 217,\n",
       " 'person': 218,\n",
       " 'things': 219,\n",
       " 'both': 220,\n",
       " 'she': 221,\n",
       " 'best': 222,\n",
       " 'comments': 223,\n",
       " 'policy': 224,\n",
       " 'part': 225,\n",
       " 'hope': 226,\n",
       " 'against': 227,\n",
       " \"can't\": 228,\n",
       " 'already': 229,\n",
       " 'keep': 230,\n",
       " 'thing': 231,\n",
       " '3': 232,\n",
       " 'u': 233,\n",
       " \"didn't\": 234,\n",
       " 'questions': 235,\n",
       " \"i'll\": 236,\n",
       " 'com': 237,\n",
       " 'nothing': 238,\n",
       " 'change': 239,\n",
       " 'wrong': 240,\n",
       " 'though': 241,\n",
       " 'subject': 242,\n",
       " 'problem': 243,\n",
       " 'remove': 244,\n",
       " 'little': 245,\n",
       " 'copyright': 246,\n",
       " 'tag': 247,\n",
       " '•': 248,\n",
       " 'trying': 249,\n",
       " 'long': 250,\n",
       " 'must': 251,\n",
       " 'understand': 252,\n",
       " 'above': 253,\n",
       " 'speedy': 254,\n",
       " 'anyone': 255,\n",
       " 'few': 256,\n",
       " 'world': 257,\n",
       " 'issue': 258,\n",
       " 'last': 259,\n",
       " 'others': 260,\n",
       " 'give': 261,\n",
       " 'editor': 262,\n",
       " 'sorry': 263,\n",
       " 'agree': 264,\n",
       " 'reliable': 265,\n",
       " 'rather': 266,\n",
       " 'let': 267,\n",
       " 'years': 268,\n",
       " 'fair': 269,\n",
       " 'english': 270,\n",
       " 'different': 271,\n",
       " 'making': 272,\n",
       " 'reference': 273,\n",
       " 'come': 274,\n",
       " 'style': 275,\n",
       " 'text': 276,\n",
       " 'references': 277,\n",
       " 'mean': 278,\n",
       " 'try': 279,\n",
       " 'non': 280,\n",
       " 'continue': 281,\n",
       " 'doing': 282,\n",
       " 'great': 283,\n",
       " 'found': 284,\n",
       " 'leave': 285,\n",
       " 'word': 286,\n",
       " 'says': 287,\n",
       " 'got': 288,\n",
       " 'state': 289,\n",
       " 'original': 290,\n",
       " \"isn't\": 291,\n",
       " 'probably': 292,\n",
       " 'site': 293,\n",
       " 'adding': 294,\n",
       " 'every': 295,\n",
       " 'check': 296,\n",
       " 'day': 297,\n",
       " 'simply': 298,\n",
       " 'created': 299,\n",
       " 'life': 300,\n",
       " 'top': 301,\n",
       " 'hello': 302,\n",
       " 'show': 303,\n",
       " 'post': 304,\n",
       " 'either': 305,\n",
       " 'consensus': 306,\n",
       " 'ip': 307,\n",
       " 'least': 308,\n",
       " 'delete': 309,\n",
       " 'else': 310,\n",
       " 'e': 311,\n",
       " 'yes': 312,\n",
       " 'view': 313,\n",
       " 'war': 314,\n",
       " 'far': 315,\n",
       " 'notable': 316,\n",
       " 'enough': 317,\n",
       " 'request': 318,\n",
       " 'etc': 319,\n",
       " 'example': 320,\n",
       " 'opinion': 321,\n",
       " 'contributions': 322,\n",
       " 'called': 323,\n",
       " 'around': 324,\n",
       " 'through': 325,\n",
       " 'www': 326,\n",
       " 'between': 327,\n",
       " 'real': 328,\n",
       " 'yet': 329,\n",
       " 'write': 330,\n",
       " 'reverted': 331,\n",
       " 'book': 332,\n",
       " 'shit': 333,\n",
       " 'down': 334,\n",
       " 'matter': 335,\n",
       " 'admin': 336,\n",
       " 're': 337,\n",
       " 'thought': 338,\n",
       " 'given': 339,\n",
       " 'images': 340,\n",
       " 'account': 341,\n",
       " 'material': 342,\n",
       " 'users': 343,\n",
       " 'bad': 344,\n",
       " 'encyclopedia': 345,\n",
       " 'having': 346,\n",
       " 'clearly': 347,\n",
       " 'title': 348,\n",
       " 'message': 349,\n",
       " 'support': 350,\n",
       " 'needs': 351,\n",
       " 'lot': 352,\n",
       " 'old': 353,\n",
       " 'evidence': 354,\n",
       " '—': 355,\n",
       " 'ever': 356,\n",
       " 's': 357,\n",
       " 'maybe': 358,\n",
       " 'tell': 359,\n",
       " 'revert': 360,\n",
       " 'seem': 361,\n",
       " 'language': 362,\n",
       " 'instead': 363,\n",
       " 'correct': 364,\n",
       " 'template': 365,\n",
       " 'org': 366,\n",
       " 'number': 367,\n",
       " 'clear': 368,\n",
       " 'media': 369,\n",
       " 'important': 370,\n",
       " 'saying': 371,\n",
       " 'pov': 372,\n",
       " '5': 373,\n",
       " '4': 374,\n",
       " 'always': 375,\n",
       " 'written': 376,\n",
       " 'true': 377,\n",
       " 'oh': 378,\n",
       " 'term': 379,\n",
       " 'further': 380,\n",
       " 'states': 381,\n",
       " 'hate': 382,\n",
       " 'perhaps': 383,\n",
       " 'quite': 384,\n",
       " 'review': 385,\n",
       " 'until': 386,\n",
       " 'bit': 387,\n",
       " 'whether': 388,\n",
       " \"i'd\": 389,\n",
       " 'research': 390,\n",
       " 'consider': 391,\n",
       " 'claim': 392,\n",
       " 'guidelines': 393,\n",
       " 'fucking': 394,\n",
       " 'version': 395,\n",
       " 'once': 396,\n",
       " 'based': 397,\n",
       " 'criteria': 398,\n",
       " 'times': 399,\n",
       " 'nigger': 400,\n",
       " 'website': 401,\n",
       " 'getting': 402,\n",
       " 'suck': 403,\n",
       " 'mention': 404,\n",
       " 'three': 405,\n",
       " 'several': 406,\n",
       " 'makes': 407,\n",
       " 'considered': 408,\n",
       " 'words': 409,\n",
       " 'c': 410,\n",
       " 'year': 411,\n",
       " 'hey': 412,\n",
       " 'changes': 413,\n",
       " 'idea': 414,\n",
       " \"there's\": 415,\n",
       " 'cannot': 416,\n",
       " 'ass': 417,\n",
       " 'address': 418,\n",
       " 'notice': 419,\n",
       " 'current': 420,\n",
       " 'group': 421,\n",
       " 'left': 422,\n",
       " 'following': 423,\n",
       " 'listed': 424,\n",
       " 'each': 425,\n",
       " 'date': 426,\n",
       " 'second': 427,\n",
       " 'means': 428,\n",
       " 'facts': 429,\n",
       " 'rules': 430,\n",
       " 'general': 431,\n",
       " 'possible': 432,\n",
       " 'main': 433,\n",
       " 'care': 434,\n",
       " 'regarding': 435,\n",
       " 'american': 436,\n",
       " 'man': 437,\n",
       " 'start': 438,\n",
       " '10': 439,\n",
       " 'topic': 440,\n",
       " 'mentioned': 441,\n",
       " 'course': 442,\n",
       " 'attack': 443,\n",
       " 'kind': 444,\n",
       " 'whole': 445,\n",
       " 'statement': 446,\n",
       " 'known': 447,\n",
       " 'end': 448,\n",
       " 'issues': 449,\n",
       " 'include': 450,\n",
       " 'seen': 451,\n",
       " 'create': 452,\n",
       " 'jpg': 453,\n",
       " 'dont': 454,\n",
       " 'en': 455,\n",
       " 'gay': 456,\n",
       " 'less': 457,\n",
       " 'related': 458,\n",
       " 'call': 459,\n",
       " 'ok': 460,\n",
       " 'sense': 461,\n",
       " 'big': 462,\n",
       " 'happy': 463,\n",
       " 'suggest': 464,\n",
       " 'category': 465,\n",
       " 'including': 466,\n",
       " 'notability': 467,\n",
       " 'info': 468,\n",
       " '2005': 469,\n",
       " 'provide': 470,\n",
       " 'redirect': 471,\n",
       " 'days': 472,\n",
       " 'move': 473,\n",
       " 'myself': 474,\n",
       " 'sentence': 475,\n",
       " \"wikipedia's\": 476,\n",
       " 'love': 477,\n",
       " 'four': 478,\n",
       " 'appropriate': 479,\n",
       " 'school': 480,\n",
       " 'news': 481,\n",
       " 'project': 482,\n",
       " 'changed': 483,\n",
       " 'explain': 484,\n",
       " 'line': 485,\n",
       " 'started': 486,\n",
       " 'neutral': 487,\n",
       " 'mind': 488,\n",
       " 'anyway': 489,\n",
       " 'contribs': 490,\n",
       " 'included': 491,\n",
       " 'removing': 492,\n",
       " 'next': 493,\n",
       " 'looking': 494,\n",
       " 't': 495,\n",
       " 'picture': 496,\n",
       " 'specific': 497,\n",
       " 'community': 498,\n",
       " 'although': 499,\n",
       " 'order': 500,\n",
       " 'per': 501,\n",
       " 'relevant': 502,\n",
       " 'sign': 503,\n",
       " 'die': 504,\n",
       " 'answer': 505,\n",
       " 'away': 506,\n",
       " 'interest': 507,\n",
       " 'full': 508,\n",
       " 'warning': 509,\n",
       " 'lol': 510,\n",
       " 'summary': 511,\n",
       " 'recent': 512,\n",
       " 'later': 513,\n",
       " 'file': 514,\n",
       " 'policies': 515,\n",
       " \"you've\": 516,\n",
       " 'faith': 517,\n",
       " 'claims': 518,\n",
       " 'discuss': 519,\n",
       " 'attacks': 520,\n",
       " 'public': 521,\n",
       " '0': 522,\n",
       " 'currently': 523,\n",
       " 'wrote': 524,\n",
       " 'writing': 525,\n",
       " 'especially': 526,\n",
       " 'interested': 527,\n",
       " 'able': 528,\n",
       " 'wish': 529,\n",
       " 'taken': 530,\n",
       " '6': 531,\n",
       " 'names': 532,\n",
       " 'position': 533,\n",
       " 'single': 534,\n",
       " 'within': 535,\n",
       " 'stuff': 536,\n",
       " 'below': 537,\n",
       " '2006': 538,\n",
       " 'during': 539,\n",
       " 'wanted': 540,\n",
       " 'web': 541,\n",
       " 'appears': 542,\n",
       " 'official': 543,\n",
       " '20': 544,\n",
       " 'live': 545,\n",
       " 'certainly': 546,\n",
       " 'nice': 547,\n",
       " 'color': 548,\n",
       " 'self': 549,\n",
       " 'itself': 550,\n",
       " 'country': 551,\n",
       " 'everyone': 552,\n",
       " 'report': 553,\n",
       " 'anti': 554,\n",
       " 'lead': 555,\n",
       " 'background': 556,\n",
       " 'high': 557,\n",
       " 'common': 558,\n",
       " 'god': 559,\n",
       " 'unless': 560,\n",
       " 'according': 561,\n",
       " 'completely': 562,\n",
       " 'hard': 563,\n",
       " 'books': 564,\n",
       " 'pretty': 565,\n",
       " '7': 566,\n",
       " 'everything': 567,\n",
       " 'p': 568,\n",
       " 'published': 569,\n",
       " 'due': 570,\n",
       " 'process': 571,\n",
       " '24': 572,\n",
       " 'edited': 573,\n",
       " 'looks': 574,\n",
       " 'involved': 575,\n",
       " 'fat': 576,\n",
       " 'therefore': 577,\n",
       " \"won't\": 578,\n",
       " 'remember': 579,\n",
       " 'obviously': 580,\n",
       " 'power': 581,\n",
       " 'd': 582,\n",
       " 'future': 583,\n",
       " 'nor': 584,\n",
       " '100': 585,\n",
       " 'truth': 586,\n",
       " 'came': 587,\n",
       " 'sandbox': 588,\n",
       " '11': 589,\n",
       " 'response': 590,\n",
       " 'party': 591,\n",
       " 'reading': 592,\n",
       " 'stay': 593,\n",
       " 'past': 594,\n",
       " 'game': 595,\n",
       " 'learn': 596,\n",
       " 'admins': 597,\n",
       " 'quote': 598,\n",
       " 'asked': 599,\n",
       " \"wasn't\": 600,\n",
       " 'b': 601,\n",
       " 'city': 602,\n",
       " 'entry': 603,\n",
       " 'stupid': 604,\n",
       " \"he's\": 605,\n",
       " 'posted': 606,\n",
       " 'false': 607,\n",
       " 'faggot': 608,\n",
       " 'whatever': 609,\n",
       " 'google': 610,\n",
       " 'talking': 611,\n",
       " 'ago': 612,\n",
       " '8': 613,\n",
       " 'placed': 614,\n",
       " 'political': 615,\n",
       " 'similar': 616,\n",
       " 'today': 617,\n",
       " 'system': 618,\n",
       " 'administrator': 619,\n",
       " 'united': 620,\n",
       " 'argument': 621,\n",
       " 'paragraph': 622,\n",
       " 'working': 623,\n",
       " 'exactly': 624,\n",
       " '2007': 625,\n",
       " 'guy': 626,\n",
       " '12': 627,\n",
       " 'british': 628,\n",
       " 'took': 629,\n",
       " 'useful': 630,\n",
       " 'government': 631,\n",
       " 'search': 632,\n",
       " 'noticed': 633,\n",
       " 'moron': 634,\n",
       " 'regards': 635,\n",
       " 'small': 636,\n",
       " 'reasons': 637,\n",
       " '2008': 638,\n",
       " 'side': 639,\n",
       " 'form': 640,\n",
       " 'dispute': 641,\n",
       " 'national': 642,\n",
       " 'deleting': 643,\n",
       " 'five': 644,\n",
       " 'guess': 645,\n",
       " 'appreciate': 646,\n",
       " 'particular': 647,\n",
       " 'reverting': 648,\n",
       " 'major': 649,\n",
       " 'problems': 650,\n",
       " 'law': 651,\n",
       " '000': 652,\n",
       " '15': 653,\n",
       " 'npov': 654,\n",
       " 'bitch': 655,\n",
       " 'rule': 656,\n",
       " 'banned': 657,\n",
       " 'often': 658,\n",
       " 'provided': 659,\n",
       " 'music': 660,\n",
       " 'become': 661,\n",
       " 'wikiproject': 662,\n",
       " 'needed': 663,\n",
       " 'status': 664,\n",
       " 'reply': 665,\n",
       " 'knowledge': 666,\n",
       " 'tried': 667,\n",
       " 'along': 668,\n",
       " 'almost': 669,\n",
       " 'cheers': 670,\n",
       " 'stated': 671,\n",
       " 'username': 672,\n",
       " 'film': 673,\n",
       " '9': 674,\n",
       " 'taking': 675,\n",
       " 'fine': 676,\n",
       " '–': 677,\n",
       " 'company': 678,\n",
       " 'vandalize': 679,\n",
       " 'present': 680,\n",
       " 'certain': 681,\n",
       " 'follow': 682,\n",
       " 'white': 683,\n",
       " 'sort': 684,\n",
       " 'otherwise': 685,\n",
       " 'terms': 686,\n",
       " 'points': 687,\n",
       " 'explanation': 688,\n",
       " 'uploaded': 689,\n",
       " \"haven't\": 690,\n",
       " 'description': 691,\n",
       " 'generally': 692,\n",
       " 'recently': 693,\n",
       " 'open': 694,\n",
       " 'entire': 695,\n",
       " 'story': 696,\n",
       " 'tags': 697,\n",
       " 'shows': 698,\n",
       " 'alone': 699,\n",
       " 'ban': 700,\n",
       " 'citation': 701,\n",
       " 'short': 702,\n",
       " 'definition': 703,\n",
       " '14': 704,\n",
       " 'cited': 705,\n",
       " 'likely': 706,\n",
       " 'aware': 707,\n",
       " 'g': 708,\n",
       " 'saw': 709,\n",
       " 'class': 710,\n",
       " 'soon': 711,\n",
       " 'type': 712,\n",
       " 'set': 713,\n",
       " 'indeed': 714,\n",
       " 'week': 715,\n",
       " 'band': 716,\n",
       " 'cite': 717,\n",
       " 'decide': 718,\n",
       " 'mr': 719,\n",
       " 'views': 720,\n",
       " '2004': 721,\n",
       " 'appear': 722,\n",
       " 'family': 723,\n",
       " 'simple': 724,\n",
       " 'area': 725,\n",
       " 'guys': 726,\n",
       " 'theory': 727,\n",
       " 'piece': 728,\n",
       " 'contact': 729,\n",
       " 'contributing': 730,\n",
       " 'external': 731,\n",
       " 'result': 732,\n",
       " 'internet': 733,\n",
       " 'interesting': 734,\n",
       " 'test': 735,\n",
       " 'unblock': 736,\n",
       " 'actual': 737,\n",
       " 'improve': 738,\n",
       " 'copy': 739,\n",
       " '16': 740,\n",
       " 'sourced': 741,\n",
       " 'told': 742,\n",
       " 'jew': 743,\n",
       " 'attention': 744,\n",
       " 'proposed': 745,\n",
       " 'obvious': 746,\n",
       " 'moved': 747,\n",
       " 'uk': 748,\n",
       " 'email': 749,\n",
       " 'members': 750,\n",
       " 'various': 751,\n",
       " 'allowed': 752,\n",
       " 'themselves': 753,\n",
       " 'context': 754,\n",
       " 'conflict': 755,\n",
       " \"article's\": 756,\n",
       " 'black': 757,\n",
       " 'university': 758,\n",
       " 'author': 759,\n",
       " 'thus': 760,\n",
       " 'disagree': 761,\n",
       " 'cunt': 762,\n",
       " 'john': 763,\n",
       " 'went': 764,\n",
       " 'citations': 765,\n",
       " 'sites': 766,\n",
       " 'jews': 767,\n",
       " 'actions': 768,\n",
       " 'hand': 769,\n",
       " 'bias': 770,\n",
       " 'previous': 771,\n",
       " 'third': 772,\n",
       " 'hours': 773,\n",
       " 'human': 774,\n",
       " '18': 775,\n",
       " 'nonsense': 776,\n",
       " 'works': 777,\n",
       " 'ones': 778,\n",
       " 'science': 779,\n",
       " 'action': 780,\n",
       " 'death': 781,\n",
       " '17': 782,\n",
       " 'enjoy': 783,\n",
       " \"aren't\": 784,\n",
       " 'job': 785,\n",
       " 'proper': 786,\n",
       " 'longer': 787,\n",
       " 'large': 788,\n",
       " 'together': 789,\n",
       " 'sucks': 790,\n",
       " '13': 791,\n",
       " '\\xa0': 792,\n",
       " \"wouldn't\": 793,\n",
       " 'addition': 794,\n",
       " 'avoid': 795,\n",
       " 'creating': 796,\n",
       " 'happened': 797,\n",
       " '19': 798,\n",
       " 'valid': 799,\n",
       " 'jewish': 800,\n",
       " 'german': 801,\n",
       " 'deal': 802,\n",
       " '21': 803,\n",
       " 'automatically': 804,\n",
       " 'biased': 805,\n",
       " 'proof': 806,\n",
       " 'worked': 807,\n",
       " 'series': 808,\n",
       " 'im': 809,\n",
       " 'dick': 810,\n",
       " 'goes': 811,\n",
       " 'himself': 812,\n",
       " 'seriously': 813,\n",
       " \"what's\": 814,\n",
       " '23': 815,\n",
       " 'level': 816,\n",
       " 'standard': 817,\n",
       " 'f': 818,\n",
       " '2009': 819,\n",
       " 'accepted': 820,\n",
       " 'respect': 821,\n",
       " 'exist': 822,\n",
       " 'available': 823,\n",
       " 'de': 824,\n",
       " 'helpful': 825,\n",
       " 'comes': 826,\n",
       " 'video': 827,\n",
       " '22': 828,\n",
       " \"shouldn't\": 829,\n",
       " 'meaning': 830,\n",
       " 'manual': 831,\n",
       " 'living': 832,\n",
       " 'opinions': 833,\n",
       " 'sex': 834,\n",
       " 'rights': 835,\n",
       " 'act': 836,\n",
       " 'tildes': 837,\n",
       " 'criticism': 838,\n",
       " '2010': 839,\n",
       " 'play': 840,\n",
       " 'necessary': 841,\n",
       " 'calling': 842,\n",
       " 'accept': 843,\n",
       " 'sections': 844,\n",
       " 'indicate': 845,\n",
       " 'personally': 846,\n",
       " 'yeah': 847,\n",
       " '30': 848,\n",
       " 'july': 849,\n",
       " 'hell': 850,\n",
       " 'statements': 851,\n",
       " 'violation': 852,\n",
       " 'accurate': 853,\n",
       " 'pig': 854,\n",
       " 'attempt': 855,\n",
       " 'assume': 856,\n",
       " 'months': 857,\n",
       " 'afd': 858,\n",
       " 'upon': 859,\n",
       " 'historical': 860,\n",
       " 'usually': 861,\n",
       " 'debate': 862,\n",
       " \"let's\": 863,\n",
       " 'pro': 864,\n",
       " 'details': 865,\n",
       " 'blocking': 866,\n",
       " 'multiple': 867,\n",
       " 'rest': 868,\n",
       " 'south': 869,\n",
       " 'tagged': 870,\n",
       " 'width': 871,\n",
       " 'serious': 872,\n",
       " 'record': 873,\n",
       " 'doubt': 874,\n",
       " 'greek': 875,\n",
       " 'm': 876,\n",
       " 'r': 877,\n",
       " \"they're\": 878,\n",
       " 'separate': 879,\n",
       " 'v': 880,\n",
       " 'space': 881,\n",
       " 'cause': 882,\n",
       " 'situation': 883,\n",
       " \"you'll\": 884,\n",
       " 'speak': 885,\n",
       " 'heard': 886,\n",
       " 'explaining': 887,\n",
       " 'okay': 888,\n",
       " 'refer': 889,\n",
       " 'fix': 890,\n",
       " 'run': 891,\n",
       " 'quality': 892,\n",
       " 'data': 893,\n",
       " 'complete': 894,\n",
       " 'penis': 895,\n",
       " 'sock': 896,\n",
       " 'church': 897,\n",
       " 'w': 898,\n",
       " 'none': 899,\n",
       " 'messages': 900,\n",
       " 'india': 901,\n",
       " 'asking': 902,\n",
       " 'august': 903,\n",
       " 'online': 904,\n",
       " 'lack': 905,\n",
       " 'legal': 906,\n",
       " 'period': 907,\n",
       " 'freedom': 908,\n",
       " 'team': 909,\n",
       " 'military': 910,\n",
       " 'behavior': 911,\n",
       " 'rationale': 912,\n",
       " 'prove': 913,\n",
       " 'apparently': 914,\n",
       " 'access': 915,\n",
       " 'special': 916,\n",
       " 'close': 917,\n",
       " 'changing': 918,\n",
       " 'bullshit': 919,\n",
       " 'directly': 920,\n",
       " 'watch': 921,\n",
       " 'culture': 922,\n",
       " 'march': 923,\n",
       " 'difference': 924,\n",
       " 'early': 925,\n",
       " 'contribute': 926,\n",
       " 'box': 927,\n",
       " 'wikipedian': 928,\n",
       " 'existing': 929,\n",
       " 'huge': 930,\n",
       " 'gets': 931,\n",
       " 'html': 932,\n",
       " 'couple': 933,\n",
       " '25': 934,\n",
       " 'among': 935,\n",
       " 'civil': 936,\n",
       " 'warring': 937,\n",
       " 'supposed': 938,\n",
       " 'primary': 939,\n",
       " 'except': 940,\n",
       " 'head': 941,\n",
       " 'countries': 942,\n",
       " 'born': 943,\n",
       " 'meant': 944,\n",
       " 'modern': 945,\n",
       " '50': 946,\n",
       " 'photo': 947,\n",
       " 'incorrect': 948,\n",
       " 'described': 949,\n",
       " 'fish': 950,\n",
       " 'uses': 951,\n",
       " 'disruptive': 952,\n",
       " 'significant': 953,\n",
       " 'field': 954,\n",
       " 'red': 955,\n",
       " 'specifically': 956,\n",
       " 'purpose': 957,\n",
       " 'pillars': 958,\n",
       " 'friend': 959,\n",
       " 'release': 960,\n",
       " 'archive': 961,\n",
       " 'million': 962,\n",
       " 'produce': 963,\n",
       " 'tv': 964,\n",
       " 'error': 965,\n",
       " 'force': 966,\n",
       " 'table': 967,\n",
       " 'earlier': 968,\n",
       " 'business': 969,\n",
       " 'computer': 970,\n",
       " 'june': 971,\n",
       " 'half': 972,\n",
       " 'sometimes': 973,\n",
       " 'cases': 974,\n",
       " 'outside': 975,\n",
       " 'vote': 976,\n",
       " 'x': 977,\n",
       " 'inclusion': 978,\n",
       " 'particularly': 979,\n",
       " 'character': 980,\n",
       " 'pictures': 981,\n",
       " 'gave': 982,\n",
       " 'linked': 983,\n",
       " 'abuse': 984,\n",
       " 'possibly': 985,\n",
       " 'control': 986,\n",
       " '27': 987,\n",
       " 'anonymous': 988,\n",
       " 'numbers': 989,\n",
       " 'home': 990,\n",
       " 'member': 991,\n",
       " 'christian': 992,\n",
       " 'january': 993,\n",
       " 'scientific': 994,\n",
       " 'arguments': 995,\n",
       " 'tutorial': 996,\n",
       " '2012': 997,\n",
       " 'n': 998,\n",
       " 'reported': 999,\n",
       " 'border': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=35000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tX_train = tokenizer.texts_to_sequences(X_train)\n",
    "padded_X_train = pad_sequences(tX_train, maxlen = 1500)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#Print word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210337"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found word vectors:  999995\n"
     ]
    }
   ],
   "source": [
    "dim = 300\n",
    "e_index = {}\n",
    "f = open('wiki-news-300d-1M.vec', encoding='utf-8')\n",
    "for line in f:\n",
    "    text = line.rstrip().rsplit(' ', dim)\n",
    "    word = text[0]\n",
    "    coefs = np.asarray(text[1:], dtype='float32')\n",
    "    e_index[word] = coefs\n",
    "f.close()\n",
    "print('Found word vectors: ', len(e_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210338, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_matrix = np.zeros((len(word_index) + 1, dim))\n",
    "for word, i in word_index.items():\n",
    "    vector = e_index.get(word)\n",
    "    if vector is not None:\n",
    "        e_matrix[i] = vector\n",
    "        \n",
    "len(e_matrix)\n",
    "e_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('embedding-2.h5', 'w') as hf:\n",
    "    hf.create_dataset('fasttext', data=e_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READING FROM THE embedding-2.h5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210338, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('embedding-2.h5', 'r') as hf:\n",
    "    mat = hf['fasttext'][:]\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1500, 300)         63101400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1500, 128)         192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 63,300,796\n",
      "Trainable params: 63,300,540\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "dim = 300\n",
    "model.add(Embedding(vocab_size + 1, dim, weights=[e_matrix], input_length=1500, trainable=True))\n",
    "\n",
    "# CNN LAYERS\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# FULLY CONNECTED LAYERS\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/2\n",
      "127656/127656 [==============================] - 2051s 16ms/step - loss: 0.0778 - accuracy: 0.9717 - val_loss: 0.0454 - val_accuracy: 0.9826\n",
      "Epoch 2/2\n",
      "127656/127656 [==============================] - 1979s 16ms/step - loss: 0.0389 - accuracy: 0.9848 - val_loss: 0.0463 - val_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x267680657c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "[X, x_test_data, y, y_test_data] = train_test_split(padded_X_train, y_train, test_size=0.2, shuffle=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size = 128, epochs = 2, validation_data = (x_test_data, y_test_data), verbose = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic:         0%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       0%\n",
      "Threat:        0%\n",
      "Insult:        0%\n",
      "Identity Hate: 0%\n"
     ]
    }
   ],
   "source": [
    "new_input = ['I am doing good']\n",
    "new_input = tokenizer.texts_to_sequences(new_input)\n",
    "new_input = pad_sequences(new_input, maxlen = 1500)\n",
    "prediction = model.predict(new_input)\n",
    "\n",
    "print('Toxic:         {:.0%}'.format(prediction[0][0]))\n",
    "print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n",
    "print('Obscene:       {:.0%}'.format(prediction[0][2]))\n",
    "print('Threat:        {:.0%}'.format(prediction[0][3]))\n",
    "print('Insult:        {:.0%}'.format(prediction[0][4]))\n",
    "print('Identity Hate: {:.0%}'.format(prediction[0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_level(string):\n",
    "    new_input = [string]\n",
    "    new_input = tokenizer.texts_to_sequences(new_input)\n",
    "    new_input = pad_sequences(new_input, maxlen = 1500)\n",
    "    prediction = model.predict(new_input)\n",
    "\n",
    "    print('Toxic:         {:.0%}'.format(prediction[0][0]))\n",
    "    print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n",
    "    print('Obscene:       {:.0%}'.format(prediction[0][2]))\n",
    "    print('Threat:        {:.0%}'.format(prediction[0][3]))\n",
    "    print('Insult:        {:.0%}'.format(prediction[0][4]))\n",
    "    print('Identity Hate: {:.0%}'.format(prediction[0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic:         11%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       0%\n",
      "Threat:        0%\n",
      "Insult:        2%\n",
      "Identity Hate: 0%\n"
     ]
    }
   ],
   "source": [
    "toxicity_level('You are wise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# # loading\n",
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('second_iter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
