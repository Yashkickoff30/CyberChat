{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\PythonProject\\chat_app\\env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('first_iter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "def toxicity_lvl_for_new_model(string):\n",
    "    new_text = [string]\n",
    "    new_text = tokenizer.texts_to_sequences(new_text)\n",
    "    new_text = pad_sequences(new_text, maxlen=1400)\n",
    "    prediction = model.predict(new_text)\n",
    "    print('Toxic:         {:.0%}'.format(prediction[0][0]))\n",
    "    print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n",
    "    print('Obscene:       {:.0%}'.format(prediction[0][2]))\n",
    "    print('Threat:        {:.0%}'.format(prediction[0][3]))\n",
    "    print('Insult:        {:.0%}'.format(prediction[0][4]))\n",
    "    print('Identity Hate: {:.0%}'.format(prediction[0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic:         6%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       0%\n",
      "Threat:        0%\n",
      "Insult:        0%\n",
      "Identity Hate: 0%\n"
     ]
    }
   ],
   "source": [
    "toxicity_lvl_for_new_model('hii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# import pickle \n",
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "integers = [1, 2, 3, 4, 5]\n",
    "\n",
    "with open('pickle-example.p', 'wb') as pfile:\n",
    "    pickle.dump(integers, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickle-example.p', 'rb') as pfile:\n",
    "    integers = pickle.load(pfile)\n",
    "    print (integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "model = keras.models.load_model('second_iter.hdf5')\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_lvl_for_new_model(string):\n",
    "    new_text = [string]\n",
    "    new_text = tokenizer.texts_to_sequences(new_text)\n",
    "    new_text = pad_sequences(new_text, maxlen=1500)\n",
    "    prediction = model.predict(new_text)\n",
    "    print('Toxic:         {:.0%}'.format(prediction[0][0]))\n",
    "    print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n",
    "    print('Obscene:       {:.0%}'.format(prediction[0][2]))\n",
    "    print('Threat:        {:.0%}'.format(prediction[0][3]))\n",
    "    print('Insult:        {:.0%}'.format(prediction[0][4]))\n",
    "    print('Identity Hate: {:.0%}'.format(prediction[0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic:         5%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       1%\n",
      "Threat:        0%\n",
      "Insult:        3%\n",
      "Identity Hate: 0%\n"
     ]
    }
   ],
   "source": [
    "toxicity_lvl_for_new_model('You are a great legend!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_detector(string):\n",
    "    prediction_result = {}\n",
    "    tags = []\n",
    "    print(name + ' : ' + string)\n",
    "    new_text = [string]\n",
    "    new_text = tokenizer.texts_to_sequences(new_text)\n",
    "    new_text = pad_sequences(new_text, maxlen=1500)\n",
    "    global graph\n",
    "    global sess\n",
    "    with graph.as_default():\n",
    "        set_session(sess)\n",
    "        prediction = model.predict(new_text)\n",
    "        toxic = round((prediction[0][0] * 100), 2)\n",
    "        s_toxic = round((prediction[0][1] * 100), 2)\n",
    "        obs = round((prediction[0][2] * 100), 2)\n",
    "        threat = round((prediction[0][3] * 100), 2)\n",
    "        insult = round((prediction[0][4] * 100), 2)\n",
    "        hate = round((prediction[0][5] * 100), 2)\n",
    "        result = round((toxic + obs + insult + hate) / 4, 2)\n",
    "        print('Result: {}'.format(result))\n",
    "        prediction_result['result'] = round(result)\n",
    "        if result > 50:\n",
    "            print('Offensive comment detected')\n",
    "            prediction_result['final_verdict'] = 'Offensive Comment Detected'\n",
    "            print('Tags related to your offensive comments: ')\n",
    "            tags = findTags(obs, insult, hate, threat, tags)\n",
    "            prediction_result['tags'] = tags\n",
    "            prediction_result['total_tags'] = len(tags)\n",
    "        else:\n",
    "            print('Good Job! No Offensive comment detected')\n",
    "            tags = findTags(obs, insult, hate, threat, tags)\n",
    "            prediction_result['final_verdict'] = 'Good Job! No Offensive comment detected'\n",
    "            prediction_result['tags'] = tags\n",
    "            prediction_result['total_tags'] = len(tags)\n",
    "            print()\n",
    "        if False:\n",
    "            print('Given String   {:}'.format(string))\n",
    "            print('Toxic:         {:}%'.format(round(toxic)))\n",
    "            print('Severe Toxic:  {:}%'.format(round(s_toxic)))\n",
    "            print('Obscene:       {:}%'.format(round(obs)))\n",
    "            print('Threat:        {:}%'.format(round(threat)))\n",
    "            print('Insult:        {:}%'.format(round(insult)))\n",
    "            print('Identity Hate: {:}%'.format(round(hate)))\n",
    "            print('Result:        {:}%'.format(result))\n",
    "        return prediction_result\n",
    "\n",
    "def findTags(obs, insult, hate, threat, tags):\n",
    "    if round(obs) >= 45:\n",
    "        print('Obscene ')\n",
    "        tags.append('Obscene')\n",
    "    if round(insult) >= 35:\n",
    "        print('Insult')\n",
    "        tags.append('Insult')\n",
    "    if round(hate) >= 30:\n",
    "        print('Hate Speech')\n",
    "        tags.append('Hate Speech')\n",
    "    if round(threat) >= 20:\n",
    "        print('Threat')\n",
    "        tags.append('Threat')\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a fool\n",
      "Result: 61.93\n",
      "Offensive comment detected\n",
      "Tags related to your offensive comments: \n",
      "Obscene \n",
      "Insult\n",
      "Given String   You are a fool\n",
      "Toxic:         98%\n",
      "Severe Toxic:  3%\n",
      "Obscene:       56%\n",
      "Threat:        0%\n",
      "Insult:        88%\n",
      "Identity Hate: 6%\n",
      "Result:        61.93%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': 62,\n",
       " 'final_verdict': 'Offensive Comment Detected',\n",
       " 'tags': ['Obscene', 'Insult'],\n",
       " 'total_tags': 2}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_detector(\"You are a fool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
